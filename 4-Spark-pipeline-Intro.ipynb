{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Pipeline Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will discuss how to search documents based on the Disease described in the CVD tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication to access covidgraph.org graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_browser = \"https://db.covidgraph.org/browser/\"\n",
    "covid_url = \"bolt://db.covidgraph.org:7687\"\n",
    "user = \"public\"\n",
    "password = \"corona\"\n",
    "\n",
    "#driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "driver = GraphDatabase.driver(uri = covid_url,\\\n",
    "                              auth = (user,password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of a paper node in the covid graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record n=<Node id=2385529 labels={'Paper'} properties={'cord_uid': 'ocp6yodg', 'cord19-fulltext_hash': 'b8957d48b6bcf17b7b51e004d19314ce77f653a1', 'journal': 'BMC Infect Dis', 'publish_time': '2011-12-28', 'source': 'PMC', 'title': 'Timeliness of contact tracing among flight passengers for influenza A/H1N1 2009', '_hash_id': '84b069ab23fb0ecebe6925af9c2b18ae', 'url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3265549/'}>>\n"
     ]
    }
   ],
   "source": [
    "paper_query = \"MATCH (n:Paper) RETURN n LIMIT 1\"\n",
    "Data = []\n",
    "with driver.session() as session:\n",
    "    info = session.run(paper_query)\n",
    "    for item in info:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fragments collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = []\n",
    "query = \"MATCH (p:Paper)-[:PAPER_HAS_BODYTEXTCOLLECTION]-(:BodyTextCollection)\\\n",
    "        -[:BODYTEXTCOLLECTION_HAS_BODYTEXT]-(:BodyText)-[:HAS_FRAGMENT]\\\n",
    "        -(f:Fragment)-[:MENTIONS]->(g:GeneSymbol) RETURN f.text limit 100\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    info = session.run(query)\n",
    "    for item in info:\n",
    "        TEXT.append(item.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark-Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as fun\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = ','.join([\n",
    "    \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.1\",\n",
    "])\n",
    "\n",
    "spark_conf = SparkConf()\n",
    "spark_conf = spark_conf.setAppName('spark1')\n",
    "spark_conf = spark_conf.setAppName('master[*]')\n",
    "spark_conf = spark_conf.set(\"spark.jars.packages\", packages)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('text', StringType()),\n",
    "])\n",
    "texts_df = spark.createDataFrame(TEXT, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|SARS and viral he...|\n",
      "|Other nation's he...|\n",
      "|MHS Kennemerland ...|\n",
      "|Requests for cont...|\n",
      "|Requests for cont...|\n",
      "|In case of Schiph...|\n",
      "|The CIb verifies ...|\n",
      "|The MHS of the ai...|\n",
      "|For tracing forei...|\n",
      "|The other interva...|\n",
      "|For the 17 comple...|\n",
      "|After acceptance ...|\n",
      "|Interval III of t...|\n",
      "|Interval III of t...|\n",
      "|Overall delay in ...|\n",
      "|Although one migh...|\n",
      "|Of the 21 request...|\n",
      "|This random-effec...|\n",
      "|This random-effec...|\n",
      "|For influenza B, ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------\n",
      " text | SARS and viral hemorrhagic fevers)                                                                   \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------\n",
      " text | Other nation's health authorities will make a request to the CIb in case they diagnosed a patient... \n",
      "-RECORD 2----------------------------------------------------------------------------------------------------\n",
      " text | MHS Kennemerland then completes contact details through booking offices or using other search met... \n",
      "-RECORD 3----------------------------------------------------------------------------------------------------\n",
      " text | Requests for contact tracing to the CIb for Dutch index patients originate from any Dutch MHS whi... \n",
      "-RECORD 4----------------------------------------------------------------------------------------------------\n",
      " text | Requests for contact tracing to the CIb for Dutch index patients originate from any Dutch MHS whi... \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts_df.show(n=5, truncate=100, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARS and viral hemorrhagic fevers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other nation's health authorities will make a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MHS Kennemerland then completes contact detail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Requests for contact tracing to the CIb for Du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Requests for contact tracing to the CIb for Du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 SARS and viral hemorrhagic fevers)\n",
       "1  Other nation's health authorities will make a ...\n",
       "2  MHS Kennemerland then completes contact detail...\n",
       "3  Requests for contact tracing to the CIb for Du...\n",
       "4  Requests for contact tracing to the CIb for Du..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain_document_ml download started this may take some time.\n",
      "Approx size to download 9.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('explain_document_ml', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': ['Hellu wrold!'],\n",
       " 'lemmas': ['Hilo', 'world', '!'],\n",
       " 'pos': ['NNP', 'NN', '.'],\n",
       " 'sentence': ['Hellu wrold!'],\n",
       " 'spell': ['Hilo', 'world', '!'],\n",
       " 'stems': ['hilo', 'world', '!'],\n",
       " 'token': ['Hellu', 'wrold', '!']}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.annotate('Hellu wrold!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "procd_texts_df = pipeline.annotate(texts_df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentence: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- spell: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- lemmas: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- stems: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- pos: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "procd_texts_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|               spell|              lemmas|               stems|                 pos|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|SARS and viral he...|[[document, 0, 33...|[[document, 0, 33...|[[token, 0, 3, SA...|[[token, 0, 3, SA...|[[token, 0, 3, SA...|[[token, 0, 3, sa...|[[pos, 0, 3, NNP,...|\n",
      "|Other nation's he...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 4, Ot...|[[token, 0, 4, Ot...|[[token, 0, 4, Ot...|[[token, 0, 4, ot...|[[pos, 0, 4, JJ, ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "procd_texts_df.show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------\n",
      " text     | SARS and viral hemorrhagic fevers)                                                                   \n",
      " document | [[document, 0, 33, SARS and viral hemorrhagic fevers), [sentence -> 0], []]]                         \n",
      " sentence | [[document, 0, 33, SARS and viral hemorrhagic fevers), [sentence -> 0], []]]                         \n",
      " token    | [[token, 0, 3, SARS, [sentence -> 0], []], [token, 5, 7, and, [sentence -> 0], []], [token, 9, 13... \n",
      " spell    | [[token, 0, 3, SARS, [confidence -> 1.0, sentence -> 0], []], [token, 5, 7, and, [confidence -> 1... \n",
      " lemmas   | [[token, 0, 3, SARS, [confidence -> 1.0, sentence -> 0], []], [token, 5, 7, and, [confidence -> 1... \n",
      " stems    | [[token, 0, 3, sar, [confidence -> 1.0, sentence -> 0], []], [token, 5, 7, and, [confidence -> 1.... \n",
      " pos      | [[pos, 0, 3, NNP, [word -> SARS], []], [pos, 5, 7, CC, [word -> and], []], [pos, 9, 13, JJ, [word... \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------\n",
      " text     | Other nation's health authorities will make a request to the CIb in case they diagnosed a patient... \n",
      " document | [[document, 0, 165, Other nation's health authorities will make a request to the CIb in case they... \n",
      " sentence | [[document, 0, 165, Other nation's health authorities will make a request to the CIb in case they... \n",
      " token    | [[token, 0, 4, Other, [sentence -> 0], []], [token, 6, 13, nation's, [sentence -> 0], []], [token... \n",
      " spell    | [[token, 0, 4, Other, [confidence -> 1.0, sentence -> 0], []], [token, 6, 13, nation's, [confiden... \n",
      " lemmas   | [[token, 0, 4, Other, [confidence -> 1.0, sentence -> 0], []], [token, 6, 13, nation's, [confiden... \n",
      " stems    | [[token, 0, 4, other, [confidence -> 1.0, sentence -> 0], []], [token, 6, 13, nation', [confidenc... \n",
      " pos      | [[pos, 0, 4, JJ, [word -> Other], []], [pos, 6, 13, JJ, [word -> nation's], []], [pos, 15, 20, NN... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "procd_texts_df.show(n=2, truncate=100, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------\n",
      " text            | SARS and viral hemorrhagic fevers)        \n",
      " finished_lemmas | [SARS, and, viral, hemorrhagic, fever, )] \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp import Finisher\n",
    "finisher = Finisher()\n",
    "finisher = finisher\n",
    "# taking the lemma column\n",
    "finisher = finisher.setInputCols(['lemmas'])\n",
    "# seperating lemmas by a single space\n",
    "finisher = finisher.setAnnotationSplitSymbol(' ')\n",
    "finished_texts_df = finisher.transform(procd_texts_df)\n",
    "finished_texts_df.show(n=1, truncate=100, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(finished_lemmas=['SARS', 'and', 'viral', 'hemorrhagic', 'fever', ')']),\n",
       " Row(finished_lemmas=['Other', \"nation's\", 'health', 'authority', 'will', 'make', 'a', 'request', 'to', 'the', 'CIb', 'in', 'case', 'they', 'diagnose', 'a', 'patient', 'which', 'arrive', 'at', 'Schiphol', 'airport', 'for', 'transit', 'while', 'be', 'infectious']),\n",
       " Row(finished_lemmas=['MHS', 'Kennemerland', 'then', 'complete', 'contact', 'detail', 'through', 'book', 'office', 'or', 'use', 'other', 'search', 'method']),\n",
       " Row(finished_lemmas=['request', 'for', 'contact', 'trace', 'to', 'the', 'CIb', 'for', 'Dutch', 'index', 'patient', 'originate', 'from', 'any', 'Dutch', 'MHS', 'which', 'identify', 'a', 'patient', 'who', 'travel', 'by', 'plane', 'while', 'be', 'contagious', 'for', 'an', 'infectious', 'disease', 'which', 'require', 'contact', 'trace']),\n",
       " Row(finished_lemmas=['request', 'for', 'contact', 'trace', 'to', 'the', 'CIb', 'for', 'Dutch', 'index', 'patient', 'originate', 'from', 'any', 'Dutch', 'MHS', 'which', 'identify', 'a', 'patient', 'who', 'travel', 'by', 'plane', 'while', 'be', 'contagious', 'for', 'an', 'infectious', 'disease', 'which', 'require', 'contact', 'trace']),\n",
       " Row(finished_lemmas=['In', 'case', 'of', 'Schiphol', ',', 'MHS', 'Kennemerland', 'approach', 'the', 'involve', 'airline', 'company', 'request', 'the', 'passenger', 'list']),\n",
       " Row(finished_lemmas=['The', 'CIb', 'verify', 'laboratory', 'confirmation', ',', 'and', 'the', 'indication', 'for', 'contact', 'trace', 'regard', 'flight', 'duration']),\n",
       " Row(finished_lemmas=['The', 'MHS', 'of', 'the', 'airport', 'where', 'the', 'specific', 'flight', 'land', 'coordinate', 'contact', 'trace', 'for', 'flight', 'passenger']),\n",
       " Row(finished_lemmas=['For', 'trace', 'foreign', 'contact', ',', 'the', 'CIb', 'send', 'a', 'notification', 'with', 'contact', 'detail', 'to', 'the', 'NFP', 'of', 'the', 'country', 'of', 'final', 'destination', ',', 'or', 'through', 'the', 'EWS', 'system', 'for', 'EU', 'country', '.']),\n",
       " Row(finished_lemmas=['The', 'other', 'interval', 'II', 'and', 'III', 'be', 'short', ',', 'with', 'a', 'mean', 'of', '0,8', 'day', 'and', '0,6', 'day', 'respectively', ',', 'see', 'Table', '1'])]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finished_texts_df.select('finished_lemmas').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
